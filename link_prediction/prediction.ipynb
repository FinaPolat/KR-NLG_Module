{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Prediction\n",
    "\n",
    "First, the Ontology will be loaded in as Graph. Then, with the help of the Jaccard Coefficient the Link per combination of celebrities will be predicted. The most interesting predictions will be kept and put in the T5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kglab.kglab.KnowledgeGraph at 0x7fbf3cc305e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the turtle data file with all the Data of the Ontology\n",
    "import sys\n",
    "#!{sys.executable} -m pip install rdflib\n",
    "\n",
    "from rdflib import Graph, ConjunctiveGraph, Literal, BNode, Namespace, RDF, URIRef\n",
    "from rdflib.namespace import DC, FOAF\n",
    "\n",
    "import kglab\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/jellewas/Documents/Master_Artificial_Intelligence/KROnTheWeb') # change directory accordingly\n",
    "\n",
    "data_points = pd.read_csv(os.getcwd() + '/query-result.csv')\n",
    "G = nx.from_pandas_edgelist(data_points, source=\"name\",target = \"occupation\",edge_attr = True,create_using=nx.MultiGraph())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Coefficient\n",
    "For our Knowledge Graph, we want to predict the Jaccard Coefficient for every possible link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_jaccard = list(nx.jaccard_coefficient(nx.Graph(G)))\n",
    "person_string = 'http://dbpedia.org/resource/'\n",
    "persons_dict = {}\n",
    "import operator\n",
    "\n",
    "for (link1, link2, score) in prediction_jaccard:\n",
    "    if person_string in str(link1):\n",
    "        if person_string in str(link2):\n",
    "            persons_dict[(link1, link2)] = score\n",
    "\n",
    "sorted_person = sorted(persons_dict.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Type\n",
    "For making reliable connections, we also want celebrities to have opposite genders. Therefore we work with a library which can guess the gender of a person based on the first name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gender-guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    "\n",
    "d = gender.Detector()\n",
    "\n",
    "linked_1_list = []\n",
    "linked_2_list = []\n",
    "\n",
    "for ((person_1, person_2), score) in sorted_person:\n",
    "   # print(f\"This Person {person_1.split('/')[-1]} is connected with this Person {person_2.split('/')[-1]} with {score}\")\n",
    "    person_1 = person_1.split('/')[-1]\n",
    "    person_1_first_name = person_1.split('_')[0]\n",
    "    \n",
    "    person_2 = person_2.split('/')[-1]\n",
    "    person_2_first_name = person_2.split('_')[0]\n",
    "    \n",
    "    person_1_gender = d.get_gender(person_1_first_name)\n",
    "    person_2_gender = d.get_gender(person_2_first_name)\n",
    "\n",
    "    male_subset = ['male', 'mostly_male']\n",
    "    female_subset = ['female', 'mostly_female']\n",
    "    \n",
    "    if person_1_gender in male_subset and person_2_gender in female_subset:\n",
    "        if person_1 not in linked_1_list:\n",
    "            if person_1 not in linked_2_list:\n",
    "                if person_2 not in linked_1_list:\n",
    "                    if person_2 not in linked_2_list:\n",
    "                        linked_1_list.append(person_1)\n",
    "                        linked_2_list.append(person_2)\n",
    "      #  print(f\"This Person {person_1} is connected with this Person {person_2} with {score}\")\n",
    "        \n",
    "        \n",
    "    elif person_1_gender in female_subset and person_2_gender in male_subset:\n",
    "        if person_1 not in linked_1_list:\n",
    "            if person_1 not in linked_2_list:\n",
    "                if person_2 not in linked_1_list:\n",
    "                    if person_2 not in linked_2_list:\n",
    "                        linked_1_list.append(person_1)\n",
    "                        linked_2_list.append(person_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrame\n",
    "Make a Pandas Dataframe from in which all the triples per celebrity that was matched according to the link prediction can be found. This Pandas DataFrame will then be transported to our T5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(columns = ['entity 1', 'entity 2', 'connected','Triple Entity 1', 'Triple Entity 2'])\n",
    "pandas_dataframe['entity 1'] = linked_1_list\n",
    "pandas_dataframe['entity 2'] = linked_2_list\n",
    "pandas_dataframe['connected'] = True\n",
    "\n",
    "dropped_columns = [1]\n",
    "pandas_dataframe.drop(dropped_columns, axis=0, inplace=True)\n",
    "\n",
    "rdf_path = os.getcwd() + '/query-result.rdf'\n",
    "\n",
    "rdf_G = Graph()\n",
    "rdf_G.parse(rdf_path)\n",
    "\n",
    "person_string = 'http://dbpedia.org/resource/'\n",
    "triples_name_1 = {}\n",
    "triples_name_2 = {}\n",
    "linked_1_list = pandas_dataframe['entity 1'].to_list()\n",
    "linked_2_list = pandas_dataframe['entity 2'].to_list()\n",
    "ex_partner = ['Carlos Leon', 'Dany Garcia', 'Jennifer Syme', 'Irina Shayk'] \n",
    "\n",
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def check_partner_year(p, o):\n",
    "    if p == 'hasPartner':\n",
    "        if has_numbers(o) == True:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def return_correct_p(string):\n",
    "    p_split = re.split('(?=[A-Z])', string)\n",
    "    p_split = p_split[0] + ' ' + p_split[1]\n",
    "    p_split = p_split.lower()\n",
    "    \n",
    "    return p_split\n",
    "    \n",
    "delete_list = ['amountWikiLinks', 'lengthPage']\n",
    "\n",
    "for (s,p,o) in rdf_G.triples((None, None, None)):\n",
    "    for (name_1, name_2) in zip(linked_1_list, linked_2_list):\n",
    "        s_split = s.split('/')[-1]\n",
    "        s_split = s_split.replace('_', ' ')\n",
    "        \n",
    "        p_split = p.split('/')[-1]\n",
    "        p_split = p_split.split('.')[-1]\n",
    "        p_split = p_split.replace('owl', '')\n",
    "        \n",
    "        o_split = o.split('/')[-1]\n",
    "        o_split = o_split.replace('_', ' ')\n",
    "        \n",
    "        if (person_string + name_1)  == str(s): \n",
    "            if name_1 in triples_name_1:\n",
    "                if p_split not in delete_list:\n",
    "                    if has_numbers(p_split) == False:\n",
    "                        if type(o_split) == str and 'myonto' not in o_split:\n",
    "                            if check_partner_year(p_split, o_split) == False:\n",
    "                                p_split = return_correct_p(p_split)\n",
    "                                if p_split in ex_partner:\n",
    "                                    final_string = s_split + ' | ' + 'had partner' + ' | ' + o_split\n",
    "                                elif p_split not in ex_partner:\n",
    "                                    final_string = s_split + ' | ' + p_split + ' | ' + o_split\n",
    "                                triples_name_1[name_1].append((final_string))\n",
    "            \n",
    "            elif name_1 not in triples_name_1:\n",
    "                if p_split not in delete_list:\n",
    "                    if has_numbers(p_split) == False:\n",
    "                        if type(o_split) == str and 'myonto' not in o_split:\n",
    "                            if check_partner_year(p_split, o_split) == False:\n",
    "                                p_split = return_correct_p(p_split)\n",
    "                                if p_split in ex_partner:\n",
    "                                    final_string = s_split + ' | ' + 'had partner' + ' | ' + o_split\n",
    "                                elif p_split not in ex_partner:\n",
    "                                    final_string = s_split + ' | ' + p_split + ' | ' + o_split\n",
    "                                triples_name_1[name_1] = [(final_string)]\n",
    "\n",
    "        elif (person_string + name_2) == str(s):\n",
    "            if name_2 in triples_name_2:\n",
    "                if p_split not in delete_list:\n",
    "                    if has_numbers(p_split) == False:\n",
    "                        if type(o_split) == str and 'myonto' not in o_split:\n",
    "                            if check_partner_year(p_split, o_split) == False:\n",
    "                                p_split = return_correct_p(p_split)\n",
    "                                if p_split in ex_partner:\n",
    "                                    final_string = s_split + ' | ' + 'had partner' + ' | ' + o_split\n",
    "                                elif p_split not in ex_partner:\n",
    "                                    final_string = s_split + ' | ' + p_split + ' | ' + o_split\n",
    "                                triples_name_2[name_2].append((final_string))\n",
    "\n",
    "            elif name_2 not in triples_name_2:\n",
    "                if has_numbers(p_split) == False:\n",
    "                    if p_split not in delete_list:\n",
    "                        if type(o_split) == str and 'myonto' not in o_split:\n",
    "                            if check_partner_year(p_split, o_split) == False:\n",
    "                                p_split = return_correct_p(p_split)\n",
    "                                if p_split in ex_partner:\n",
    "                                    final_string = s_split + ' | ' + 'had partner' + ' | ' + o_split\n",
    "                                elif p_split not in ex_partner:\n",
    "                                    final_string = s_split + ' | ' + p_split + ' | ' + o_split\n",
    "                                triples_name_2[name_2] = [(final_string)]\n",
    "                            \n",
    "for index, row in pandas_dataframe.iterrows():\n",
    "    pandas_dataframe.at[index, 'Triple Entity 1'] = triples_name_1[row['entity 1']]\n",
    "    pandas_dataframe.at[index, 'Triple Entity 2'] = triples_name_2[row['entity 2']]\n",
    "\n",
    "pandas_dataframe.to_csv(os.getcwd() + '/MatchesLink.tsv', sep ='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
